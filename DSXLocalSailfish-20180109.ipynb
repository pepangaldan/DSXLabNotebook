{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"border: none\" align=\"left\">\n",
    "   <tr style=\"border: none\">\n",
    "      <th style=\"border: none\"><font face=\"verdana\" size=\"5\" color=\"black\"><center><b>Predicting Outdoor Equipment Purchases<br><br> with Data Science Experience Local<br><br> on the IBM Integrated Analytics System</b></center></font></th>\n",
    "   </tr>\n",
    "   <tr style=\"border: none\">\n",
    "       <th style=\"border: none\"><img src=\"https://github.com/pmservice/wml-sample-models/blob/master/spark/product-line-prediction/images/products_graphics.png?raw=true\" alt=\"Icon\"> </th>\n",
    "   </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides steps and code to load data from Db2 Warehouse on Cloud, explore this data, create a predictive model, deploy and start scoring with new data. In addition, it introduces basic data cleansing and exploration, pipeline creation, model training, model persistence, model deployment, predictions and scoring.\n",
    "\n",
    "Some familiarity with Python is helpful. This notebook uses Python 2.0 and Apache® Spark 2.0.\n",
    "\n",
    "The data is publically available and contains anonymous outdoor equipment purchases.  It can also be downloaded here [GoSales Transactions](https://apsportal.ibm.com/exchange-api/v1/entries/8044492073eb964f46597b4be06ff5ea/data?accessKey=9561295fa407698694b1e254d0099600).  Based on this data, interest in product lines (golf accessories, camping equipment, etc.) will be predicted based on a consumer's gender, age, marital status and job.\n",
    "\n",
    "\n",
    "## Learning goals\n",
    "\n",
    "The learning goals of this notebook are:\n",
    "\n",
    "-  Load data into an Apache® Spark DataFrame.\n",
    "-  Explore data.\n",
    "-  Prepare data for training and evaluation.\n",
    "-  Create an Apache® Spark machine learning pipeline.\n",
    "-  Train and evaluate a model.\n",
    "-  Persist a pipeline and model.\n",
    "-  Deploy a model for online scoring.\n",
    "-  Score with sample data.\n",
    "-  Explore and visualize prediction results using the plotly package.\n",
    "\n",
    "\n",
    "## Contents\n",
    "\n",
    "This notebook contains the following parts:\n",
    "\n",
    "1.\t[Load and explore data](#load)\n",
    "2.\t[Create spark ml model](#model)\n",
    "3.\t[Persist model](#persistence)\n",
    "4.\t[Predict locally and visualize](#visualization)\n",
    "5.\t[Deploy and score](#scoring)\n",
    "7.\t[Summary and next steps](#summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"load\"></a>\n",
    "## 1. Load and explore data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section you will load the data as an Apache® Spark DataFrame and perform basic exploration.  First, a SparkSession will be created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GOSales data will be loaded into a Spark dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_data = spark.read.format('jdbc').options(\n",
    "          url='jdbc:db2://dashdb-entry-yp-dal09-09.services.dal.bluemix.net:50000/BLUDB',\n",
    "          driver='com.ibm.db2.jcc.DB2Driver',\n",
    "          dbtable='dash7268.GOSALES',\n",
    "          user='dash7268',\n",
    "          password='mV@$e7q4RPzL').load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Explore the loaded data by using the following Apache® Spark DataFrame methods:\n",
    "-  print schema\n",
    "-  print top ten records\n",
    "-  count all records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PRODUCT_LINE: string (nullable = true)\n",
      " |-- GENDER: string (nullable = true)\n",
      " |-- AGE: integer (nullable = true)\n",
      " |-- MARITAL_STATUS: string (nullable = true)\n",
      " |-- PROFESSION: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the data contains five fields. PRODUCT_LINE field is the one we would like to predict (label)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+---+--------------+------------+\n",
      "|        PRODUCT_LINE|GENDER|AGE|MARITAL_STATUS|  PROFESSION|\n",
      "+--------------------+------+---+--------------+------------+\n",
      "|Mountaineering Eq...|     M| 33|        Single|       Other|\n",
      "|Mountaineering Eq...|     M| 32|        Single|      Trades|\n",
      "|Mountaineering Eq...|     M| 32|        Single|      Trades|\n",
      "|   Camping Equipment|     M| 32|        Single|      Trades|\n",
      "|      Golf Equipment|     M| 32|        Single|      Trades|\n",
      "|   Camping Equipment|     F| 28|        Single|       Other|\n",
      "|   Camping Equipment|     F| 28|        Single|       Other|\n",
      "|   Camping Equipment|     F| 28|        Single|       Other|\n",
      "|      Golf Equipment|     M| 54|       Married|Professional|\n",
      "|      Golf Equipment|     M| 54|       Married|Professional|\n",
      "|   Camping Equipment|     F| 34|       Married| Hospitality|\n",
      "|   Camping Equipment|     F| 34|       Married| Hospitality|\n",
      "|   Camping Equipment|     F| 34|       Married| Hospitality|\n",
      "|Personal Accessories|     F| 26|       Married|       Sales|\n",
      "|Personal Accessories|     F| 26|       Married|       Sales|\n",
      "|Mountaineering Eq...|     M| 46|       Married|Professional|\n",
      "|   Camping Equipment|     M| 46|       Married|Professional|\n",
      "|Personal Accessories|     M| 46|       Married|Professional|\n",
      "|Mountaineering Eq...|     M| 41|       Married|   Executive|\n",
      "|   Camping Equipment|     M| 41|       Married|   Executive|\n",
      "+--------------------+------+---+--------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60252"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the data set contains 60252 records."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"model\"></a>\n",
    "## 2. Create an Apache® Spark machine learning model\n",
    "\n",
    "In this section you will learn how to prepare data, create an Apache® Spark machine learning pipeline, and train a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1: Prepare data\n",
    "\n",
    "In this subsection you will split your data into: train, test and predict datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training records: 48176\n",
      "Number of testing records : 10860\n",
      "Number of prediction records : 1216\n"
     ]
    }
   ],
   "source": [
    "splitted_data = df_data.randomSplit([0.8, 0.18, 0.02], 24)\n",
    "train_data = splitted_data[0]\n",
    "test_data = splitted_data[1]\n",
    "predict_data = splitted_data[2]\n",
    "\n",
    "print \"Number of training records: \" + str(train_data.count())\n",
    "print \"Number of testing records : \" + str(test_data.count())\n",
    "print \"Number of prediction records : \" + str(predict_data.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see our data has been successfully split into three datasets: \n",
    "\n",
    "-  The train data set, which is the largest group, is used for training.\n",
    "-  The test data set will be used for model evaluation and is used to test the assumptions of the model.\n",
    "-  The predict data set will be used for prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2: Create pipeline and train a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section you will create an Apache® Spark machine learning pipeline and then train the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first step you need to import the Apache® Spark machine learning packages that will be needed in the subsequent steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, IndexToString, VectorAssembler\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml import Pipeline, Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following step, convert all the string fields to numeric ones by using the StringIndexer transformer.  This encodes a string column to a column of indices that the machine learning algorithm can consume and evaluate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stringIndexer_label = StringIndexer(inputCol=\"PRODUCT_LINE\", outputCol=\"label\").fit(df_data)\n",
    "stringIndexer_prof = StringIndexer(inputCol=\"PROFESSION\", outputCol=\"PROFESSION_IX\")\n",
    "stringIndexer_gend = StringIndexer(inputCol=\"GENDER\", outputCol=\"GENDER_IX\")\n",
    "stringIndexer_mar = StringIndexer(inputCol=\"MARITAL_STATUS\", outputCol=\"MARITAL_STATUS_IX\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following step, create a feature vector by combining all features together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorAssembler_features = VectorAssembler(inputCols=[\"GENDER_IX\", \"AGE\", \"MARITAL_STATUS_IX\", \"PROFESSION_IX\"], outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, define estimators you want to use for classification. Random Forest is used in the following example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, bring indexed labels back to original labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\", labels=stringIndexer_label.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build the pipeline now. A pipeline consists of transformers and an estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline_rf = Pipeline(stages=[stringIndexer_label, stringIndexer_prof, stringIndexer_gend, stringIndexer_mar, vectorAssembler_features, rf, labelConverter])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you can train your Random Forest model by using the previously defined **pipeline** and **train data**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_rf = pipeline_rf.fit(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check your **model accuracy** now. To evaluate the model, use **test data**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.589319\n"
     ]
    }
   ],
   "source": [
    "predictions = model_rf.transform(test_data)\n",
    "evaluatorRF = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluatorRF.evaluate(predictions)\n",
    "print(\"Accuracy = %g\" % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Greater accuracy might be achieved using more data, regularization, normalization or other techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id=\"persistence\"></a>\n",
    "## 3. Persist model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section you will learn how to store your pipeline and model by using Python client libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "First, you must import client libraries.\n",
    "\n",
    "**Note**: Apache® Spark 2.0 or higher is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from repository.mlrepositoryclient import MLRepositoryClient\n",
    "from repository.mlrepositoryartifact import MLRepositoryArtifact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the service path and create a machine learning repository client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "service_path = 'https://internal-nginx-svc.ibm-private-cloud.svc.cluster.local:12443'\n",
    "ml_repository_client = MLRepositoryClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create model artifact (abstraction layer).<br>\n",
    "<font color=\"red\">**Tip**: Make sure to replace the **XX** in the following code cell with your team number to identify yours from the other teams.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_artifact = MLRepositoryArtifact(model_rf, training_data=train_data, name=\"Product Line Prediction\")\n",
    "model_artifact.meta.add(\"authorName\", \"Team 00\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tip**: The MLRepositoryArtifact method expects a trained model object, training data, and a model name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1: Save pipeline and model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this subsection you will learn how to save pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saved_model = ml_repository_client.models.save(model_artifact)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get saved model metadata."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tip**: Use *meta.available_props()* to get the list of available props."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['inputDataSchema',\n",
       " 'evaluationMetrics',\n",
       " 'pipelineType',\n",
       " 'trainingDataRef',\n",
       " 'authorUID',\n",
       " 'lastUpdated',\n",
       " 'modelType',\n",
       " 'projectGuid',\n",
       " 'modelVersionHref',\n",
       " 'pipelineVersionHref',\n",
       " 'projectId',\n",
       " 'creationTime',\n",
       " 'label',\n",
       " 'authorEmail',\n",
       " 'trainingDataSchema',\n",
       " 'authorName',\n",
       " 'version',\n",
       " 'runtime',\n",
       " 'evaluationMethod']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_model.meta.available_props()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modelType: sparkml-model-2.0\n",
      "trainingDataSchema: {u'fields': [{u'nullable': True, u'type': u'string', u'name': u'PRODUCT_LINE', u'metadata': {u'scale': 0, u'name': u'PRODUCT_LINE'}}, {u'nullable': True, u'type': u'string', u'name': u'GENDER', u'metadata': {u'scale': 0, u'name': u'GENDER'}}, {u'nullable': True, u'type': u'integer', u'name': u'AGE', u'metadata': {u'scale': 0, u'name': u'AGE'}}, {u'nullable': True, u'type': u'string', u'name': u'MARITAL_STATUS', u'metadata': {u'scale': 0, u'name': u'MARITAL_STATUS'}}, {u'nullable': True, u'type': u'string', u'name': u'PROFESSION', u'metadata': {u'scale': 0, u'name': u'PROFESSION'}}], u'type': u'struct'}\n",
      "creationTime: 2017-12-07 23:03:23.005000+00:00\n",
      "modelVersionHref: https://internal-nginx-svc.ibm-private-cloud.svc.cluster.local:12443/v2/artifacts/models/95382a89-d74d-4e5d-8102-72ff1828ed5e/versions/97f32053-89a5-4176-82fd-19c48574bc5f\n",
      "label: PRODUCT_LINE\n"
     ]
    }
   ],
   "source": [
    "print \"modelType: \" + saved_model.meta.prop(\"modelType\")\n",
    "print \"trainingDataSchema: \" + str(saved_model.meta.prop(\"trainingDataSchema\"))\n",
    "print \"creationTime: \" + str(saved_model.meta.prop(\"creationTime\"))\n",
    "print \"modelVersionHref: \" + saved_model.meta.prop(\"modelVersionHref\")\n",
    "print \"label: \" + saved_model.meta.prop(\"label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tip**: **modelVersionHref** is the unique model indentifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2: Load model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this subsection you will learn how to load back saved model from specified instance of Watson Machine Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loadedModelArtifact = ml_repository_client.models.get(saved_model.uid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can print for example model name to make sure that model has been loaded correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product Line Prediction\n"
     ]
    }
   ],
   "source": [
    "print str(loadedModelArtifact.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the name is correct. You have successfully saved and loaded the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"visualization\"></a>\n",
    "## 4. Predict locally and visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will score test data using the loaded model and visualize the prediction results with plotly package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1: Make local prediction using previously loaded model and test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this subsection you will score *predict_data* data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = loadedModelArtifact.model_instance().transform(predict_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preview the results by calling the *show()* method on the predictions DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------+---+--------------+----------+-----+-------------+---------+-----------------+------------------+--------------------+--------------------+----------+--------------------+\n",
      "|     PRODUCT_LINE|GENDER|AGE|MARITAL_STATUS|PROFESSION|label|PROFESSION_IX|GENDER_IX|MARITAL_STATUS_IX|          features|       rawPrediction|         probability|prediction|      predictedLabel|\n",
      "+-----------------+------+---+--------------+----------+-----+-------------+---------+-----------------+------------------+--------------------+--------------------+----------+--------------------+\n",
      "|Camping Equipment|     F| 20|        Single|     Other|  0.0|          0.0|      1.0|              1.0|[1.0,20.0,1.0,0.0]|[5.54119162527029...|[0.27705958126351...|       1.0|Personal Accessories|\n",
      "|Camping Equipment|     F| 20|        Single|     Other|  0.0|          0.0|      1.0|              1.0|[1.0,20.0,1.0,0.0]|[5.54119162527029...|[0.27705958126351...|       1.0|Personal Accessories|\n",
      "|Camping Equipment|     F| 20|        Single|     Other|  0.0|          0.0|      1.0|              1.0|[1.0,20.0,1.0,0.0]|[5.54119162527029...|[0.27705958126351...|       1.0|Personal Accessories|\n",
      "|Camping Equipment|     F| 20|        Single|     Other|  0.0|          0.0|      1.0|              1.0|[1.0,20.0,1.0,0.0]|[5.54119162527029...|[0.27705958126351...|       1.0|Personal Accessories|\n",
      "|Camping Equipment|     F| 21|       Married|     Other|  0.0|          0.0|      1.0|              0.0|[1.0,21.0,0.0,0.0]|[8.54473640086929...|[0.42723682004346...|       0.0|   Camping Equipment|\n",
      "+-----------------+------+---+--------------+----------+-----+-------------+---------+-----------------+------------------+--------------------+--------------------+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By tabulating a count, you can see which product line is the most popular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|      predictedLabel|count|\n",
      "+--------------------+-----+\n",
      "|   Camping Equipment|  717|\n",
      "|      Golf Equipment|   61|\n",
      "|Mountaineering Eq...|   75|\n",
      "|Personal Accessories|  363|\n",
      "+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.select(\"predictedLabel\").groupBy(\"predictedLabel\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2: Sample visualization of data with Plotly package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this subsection you will explore prediction results with Plotly, which is an online analytics and data visualization tool."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: If you experience errors in this next code cell, you may need to install the required packages.  This can be done by issuing the following but only needs to be run one time.\n",
    "\n",
    "!pip install plotly --user <BR>\n",
    "!pip install cufflinks==0.8.2 --user\n",
    "<br><br>\n",
    "Import Plotly and other required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-6838ef923a0d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph_objs\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mgo\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0minit_notebook_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconnected\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"HOME\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas\n",
    "import plotly.plotly as py\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "import cufflinks as cf\n",
    "import plotly.graph_objs as go\n",
    "init_notebook_mode(connected=True)\n",
    "sys.path.append(\"\".join([os.environ[\"HOME\"]])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the Apache Spark DataFrame to a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions_pdf = predictions.select(\"prediction\", \"predictedLabel\", \"GENDER\", \"AGE\", \"PROFESSION\", \"MARITAL_STATUS\").toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot a pie chart that shows the predicted product-line interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cumulative_stats = predictions_pdf.groupby(['predictedLabel']).count()\n",
    "\n",
    "product_data = [go.Pie(\n",
    "            labels=cumulative_stats.index,\n",
    "            values=cumulative_stats['GENDER'],\n",
    "    )]\n",
    "\n",
    "product_layout = go.Layout(\n",
    "    title='Predicted product line client interest distribution',\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=product_data, layout=product_layout)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this data set, you might want to do some analysis of the mean AGE per product line by using a bar chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "age_data = [go.Bar(\n",
    "            y=predictions_pdf.groupby(['predictedLabel']).mean()[\"AGE\"],\n",
    "            x=cumulative_stats.index\n",
    "            \n",
    "    )]\n",
    "\n",
    "age_layout = go.Layout(\n",
    "    title='Mean AGE per predicted product line',\n",
    "    xaxis=dict(\n",
    "        title = \"Product Line\",\n",
    "        showline=False,),\n",
    "    yaxis=dict(\n",
    "        title = \"Mean AGE\",\n",
    "        ),\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=age_data, layout=age_layout)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on bar plot you created, you might make the following conclusion: The mean age for clients that are interested in golf equipment is predicted to be around 50 years old."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"scoring\"></a>\n",
    "## 5. Deploy and score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section you will learn how to create online scoring and to score a new data record. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Data Science Experience Local user interface will be used to deploy the model that we previously saved.\n",
    "<font color=\"red\">Please go through the following steps carefully.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    
    " Note: Be Sure you use the correct Wed address for item 1 below using the Web Link given for your group. <br>\n",
    " Shown below is the web link for Group 1 <br>\n",
    " " 
    
    "1) Click here https://amazingkalam.bluedemos.skytapdns.com/auth/login/login.html to open another browser tab for DSX Local.<br>\n",
    "2) Click on the hamburger icon, then click on 'Model Management' and 'Models'.<br>\n",
    "3) Find the model you saved by looking under 'Publisher' for your team name and number. For example Model: Product Line Prediction Publisher : Team00 <br>\n",
    "4) Click on the '...' and select 'Deploy'.<br>\n",
    "5) On the next screen, 'Name' is Team Name (eg.TEAM00), 'Type' : Online.  Click Create'.  Your saved model will now appear under 'Deployments'.<br>\n",
    "6) Click your Team Name (eg Team00) under 'Deployment Name'.<br>\n",
    "7) Click 'Test API' on upper right corner. <br>\n",
    "8) For Input data labels GENDER, AGE, MARITAL_STATUS, PROFESSION values are M,23,Single,Student. Click 'Predict'.<br>\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see we predict that a 23-year-old male student is interested in personal accessories (predictedLabel: Personal Accessories, prediction: 1.0). \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id=\"summary\"></a>\n",
    "## 6. Summary and next steps     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " You successfully completed this notebook! You learned how to use Apache Spark machine learning for model creation and deployment. Check out our [Online Documentation](https://console.ng.bluemix.net/docs/services/PredictiveModeling/pm_service_api_spark.html) for more samples, tutorials, documentation, how-tos, and blog posts. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acknowledgement\n",
    "\n",
    "This notebook is based on the work of Lukasz Cmielowski, PhD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright © 2017 IBM. This notebook and its source code are released under the terms of the MIT License."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
